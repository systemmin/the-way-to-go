import{_ as t,c as p,a as s,d as e,o as l,r as o}from"./app-DtITwm2S.js";const i={};function c(r,n){const a=o("CodeDesc");return l(),p("div",null,[n[0]||(n[0]=s(`<h1 id="嵌入" tabindex="-1"><a class="header-anchor" href="#嵌入"><span><a href="https://platform.openai.com/docs/guides/embeddings/embeddings" target="_blank" rel="noopener noreferrer">嵌入</a></span></a></h1><h2 id="什么是嵌入" tabindex="-1"><a class="header-anchor" href="#什么是嵌入"><span>什么是嵌入？</span></a></h2><p>OpenAI 的文本嵌入衡量文本字符串的相关性。嵌入通常用于：</p><ul><li><strong>搜索</strong>（结果按与查询字符串的相关性排序）</li><li><strong>聚类</strong>（其中文本字符串按相似性分组）</li><li><strong>推荐</strong>（推荐具有相关文本字符串的项目）</li><li><strong>异常检测</strong>（识别出相关性很小的异常值）</li><li><strong>多样性测量</strong>（分析相似性分布）</li><li><strong>分类</strong>（其中文本字符串按其最相似的标签分类）</li></ul><p>嵌入是浮点数的向量（列表）。两个向量之间的<a href="https://platform.openai.com/docs/guides/embeddings/which-distance-function-should-i-use" target="_blank" rel="noopener noreferrer">距离</a>衡量它们的相关性。小距离表示高相关性，大距离表示低相关性。</p><p>访问我们的<a href="https://openai.com/api/pricing/" target="_blank" rel="noopener noreferrer">定价页面</a>以了解嵌入定价。请求根据发送的<a href="https://platform.openai.com/docs/api-reference/embeddings/create#embeddings/create-input" target="_blank" rel="noopener noreferrer">输入</a>中的<a href="https://platform.openai.com/tokenizer" target="_blank" rel="noopener noreferrer">标记</a>数量计费。</p><blockquote><p><strong>要查看嵌入的实际效果，请查看我们的代码示例</strong></p><ul><li>分类</li><li>主题聚类</li><li>搜索</li><li>建议</li></ul><p><a href="https://platform.openai.com/docs/guides/embeddings/use-cases" target="_blank" rel="noopener noreferrer">浏览示例</a></p></blockquote><h3 id="如何获得嵌入" tabindex="-1"><a class="header-anchor" href="#如何获得嵌入"><span>如何获得嵌入</span></a></h3><p>要获得嵌入，请将您的文本字符串连同选择的嵌入模型 ID（例如， ）发送到<a href="https://platform.openai.com/docs/api-reference/embeddings" target="_blank" rel="noopener noreferrer">嵌入 API 端点</a><code>text-embedding-ada-002</code>。响应将包含一个嵌入，您可以提取、保存和使用它。</p><p>示例请求：</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line"><span class="token function">curl</span> https://api.openai.com/v1/embeddings <span class="token punctuation">\\</span></span>
<span class="line">  <span class="token parameter variable">-H</span> <span class="token string">&quot;Content-Type: application/json&quot;</span> <span class="token punctuation">\\</span></span>
<span class="line">  <span class="token parameter variable">-H</span> <span class="token string">&quot;Authorization: Bearer <span class="token variable">$OPENAI_API_KEY</span>&quot;</span> <span class="token punctuation">\\</span></span>
<span class="line">  <span class="token parameter variable">-d</span> <span class="token string">&#39;{&quot;input&quot;: &quot;Your text string goes here&quot;,</span>
<span class="line">       &quot;model&quot;:&quot;text-embedding-ada-002&quot;}&#39;</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>示例响应：</p><div class="language-json line-numbers-mode" data-highlighter="prismjs" data-ext="json" data-title="json"><pre><code><span class="line"><span class="token punctuation">{</span></span>
<span class="line">  <span class="token property">&quot;data&quot;</span><span class="token operator">:</span> <span class="token punctuation">[</span></span>
<span class="line">    <span class="token punctuation">{</span></span>
<span class="line">      <span class="token property">&quot;embedding&quot;</span><span class="token operator">:</span> <span class="token punctuation">[</span></span>
<span class="line">        <span class="token number">-0.006929283495992422</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token number">-0.005336422007530928</span><span class="token punctuation">,</span></span>
<span class="line">        ...</span>
<span class="line">        <span class="token number">-4.547132266452536e-05</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token number">-0.024047505110502243</span></span>
<span class="line">      <span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">      <span class="token property">&quot;index&quot;</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span></span>
<span class="line">      <span class="token property">&quot;object&quot;</span><span class="token operator">:</span> <span class="token string">&quot;embedding&quot;</span></span>
<span class="line">    <span class="token punctuation">}</span></span>
<span class="line">  <span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;model&quot;</span><span class="token operator">:</span> <span class="token string">&quot;text-embedding-ada-002&quot;</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;object&quot;</span><span class="token operator">:</span> <span class="token string">&quot;list&quot;</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;usage&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span></span>
<span class="line">    <span class="token property">&quot;prompt_tokens&quot;</span><span class="token operator">:</span> <span class="token number">5</span><span class="token punctuation">,</span></span>
<span class="line">    <span class="token property">&quot;total_tokens&quot;</span><span class="token operator">:</span> <span class="token number">5</span></span>
<span class="line">  <span class="token punctuation">}</span></span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><a href="https://github.com/openai/openai-cookbook/" target="_blank" rel="noopener noreferrer">在OpenAI Cookbook</a>中查看更多 Python 代码示例。</p><p>使用 OpenAI 嵌入时，请牢记它们的<a href="https://platform.openai.com/docs/guides/embeddings/limitations-risks" target="_blank" rel="noopener noreferrer">局限性和风险</a>。</p><h3 id="嵌入模型" tabindex="-1"><a class="header-anchor" href="#嵌入模型"><span>嵌入模型</span></a></h3><p>OpenAI 提供了一个第二代嵌入模型（<code>-002</code>在模型 ID 中表示）和 16 个第一代模型（<code>-001</code>在模型 ID 中表示）。</p><p>我们建议对几乎所有用例使用 text-embedding-ada-002。它更好、更便宜、更易于使用。阅读<a href="https://openai.com/blog/new-and-improved-embedding-model" target="_blank" rel="noopener noreferrer">博文公告</a>。</p><table><thead><tr><th style="text-align:left;">模型生成</th><th style="text-align:left;">分词器</th><th style="text-align:left;">最大输入令牌</th><th style="text-align:left;">知识截断</th></tr></thead><tbody><tr><td style="text-align:left;">V2</td><td style="text-align:left;">cl100k_base</td><td style="text-align:left;">8191</td><td style="text-align:left;">2021 年 9 月</td></tr><tr><td style="text-align:left;">V1</td><td style="text-align:left;">GPT-2/GPT-3</td><td style="text-align:left;">2046</td><td style="text-align:left;">2020 年 8 月</td></tr></tbody></table><p>使用量按输入令牌定价，每 1000 个令牌 0.0004 美元，或每美元约 3,000 页（假设每页约 800 个令牌）：</p><table><thead><tr><th style="text-align:left;">模型</th><th style="text-align:left;">每美元粗页</th><th style="text-align:left;"><a href="https://paperswithcode.com/sota/zero-shot-text-search-on-beir" target="_blank" rel="noopener noreferrer">BEIR</a>搜索评估的示例性能</th></tr></thead><tbody><tr><td style="text-align:left;">text-embedding-ada-002</td><td style="text-align:left;">3000</td><td style="text-align:left;">53.9</td></tr><tr><td style="text-align:left;">*-davinci-*-001</td><td style="text-align:left;">6个</td><td style="text-align:left;">52.8</td></tr><tr><td style="text-align:left;">*-curie-*-001</td><td style="text-align:left;">60</td><td style="text-align:left;">50.9</td></tr><tr><td style="text-align:left;">*-babbage-*-001</td><td style="text-align:left;">240</td><td style="text-align:left;">50.4</td></tr><tr><td style="text-align:left;">*-ada-*-001</td><td style="text-align:left;">300</td><td style="text-align:left;">49.0</td></tr></tbody></table><h3 id="二代模型" tabindex="-1"><a class="header-anchor" href="#二代模型"><span>二代模型</span></a></h3><table><thead><tr><th style="text-align:left;">型号名称</th><th style="text-align:left;">分词器</th><th style="text-align:left;">最大输入令牌</th><th style="text-align:left;">输出尺寸</th></tr></thead><tbody><tr><td style="text-align:left;">文本嵌入-ada-002</td><td style="text-align:left;">cl100k_base</td><td style="text-align:left;">8191</td><td style="text-align:left;">1536</td></tr></tbody></table><details class="hint-container details"><summary>第一代模型（不推荐）</summary><p>所有第一代模型（以 -001 结尾的模型）都使用<a href="https://platform.openai.com/tokenizer" target="_blank" rel="noopener noreferrer">GPT-3 分词</a>器，最大输入为 2046 个分词。</p><p>第一代嵌入由五个不同的模型系列生成，这些模型系列针对三个不同的任务进行了调整：文本搜索、文本相似性和代码搜索。搜索模型成对出现：一个用于短查询，一个用于长文档。每个系列最多包括四种质量和速度不同的型号：</p><table><thead><tr><th style="text-align:left;">模型</th><th style="text-align:left;">输出尺寸</th></tr></thead><tbody><tr><td style="text-align:left;">Ada</td><td style="text-align:left;">1024</td></tr><tr><td style="text-align:left;">Babbage</td><td style="text-align:left;">2048</td></tr><tr><td style="text-align:left;">Curie</td><td style="text-align:left;">4096</td></tr><tr><td style="text-align:left;">Davinci</td><td style="text-align:left;">12288</td></tr></tbody></table><p>Davinci 是最有能力的，但比其他型号更慢且更昂贵。Ada 的能力最差，但速度更快，成本更低。</p><h4 id="相似性嵌入" tabindex="-1"><a class="header-anchor" href="#相似性嵌入"><span>相似性嵌入</span></a></h4><p>相似性模型最擅长捕捉文本片段之间的语义相似性。</p><table><thead><tr><th style="text-align:left;">用例</th><th style="text-align:left;">可用型号</th></tr></thead><tbody><tr><td style="text-align:left;">聚类、回归、异常检测、可视化</td><td style="text-align:left;"><code>text-similarity-ada-001</code><br> <code>text-similarity-babbage-001</code><br> <code>text-similarity-curie-001</code> <br><code>text-similarity-davinci-001</code></td></tr></tbody></table><h4 id="文本搜索嵌入" tabindex="-1"><a class="header-anchor" href="#文本搜索嵌入"><span>文本搜索嵌入</span></a></h4><p>文本搜索模型有助于衡量哪些长文档与短搜索查询最相关。使用了两种模型：一种用于嵌入搜索查询，一种用于嵌入要排名的文档。最接近查询嵌入的文档嵌入应该是最相关的。</p><table><thead><tr><th style="text-align:left;">用例</th><th style="text-align:left;">可用型号</th></tr></thead><tbody><tr><td style="text-align:left;">搜索、上下文相关性、信息检索</td><td style="text-align:left;"><code>text-search-ada-doc-001</code> <br> <code>text-search-ada-query-001</code> <br> <code>text-search-babbage-doc-001</code> <br> <code>text-search-babbage-query-001</code> <br> <code>text-search-curie-doc-001</code> <br> <code>text-search-curie-query-001</code> <br> <code>text-search-davinci-doc-001</code> <br> <code>text-search-davinci-query-001</code></td></tr></tbody></table><h4 id="代码搜索嵌入" tabindex="-1"><a class="header-anchor" href="#代码搜索嵌入"><span>代码搜索嵌入</span></a></h4><p>与搜索嵌入类似，有两种类型：一种用于嵌入自然语言搜索查询，一种用于嵌入要检索的代码片段。</p><table><thead><tr><th style="text-align:left;">用例</th><th style="text-align:left;">可用型号</th></tr></thead><tbody><tr><td style="text-align:left;">代码搜索和相关性</td><td style="text-align:left;"><code>code-search-ada-code-001</code> <br> <code>code-search-ada-text-001</code> <br> <code>code-search-babbage-code-001</code> <br> <code>code-search-babbage-text-001</code></td></tr></tbody></table><div class="hint-container warning"><p class="hint-container-title">提示</p><p>对于<code>-001</code>文本嵌入（不是<code>-002</code>, 和代码嵌入），我们建议将<code>\\n</code>输入中的换行符 ( ) 替换为单个空格，因为当存在换行符时我们已经看到更糟糕的结果。</p></div></details><h2 id="用例" tabindex="-1"><a class="header-anchor" href="#用例"><span>用例</span></a></h2><p>在这里，我们展示了一些有代表性的用例。我们将在以下示例中使用<a href="https://www.kaggle.com/snap/amazon-fine-food-reviews" target="_blank" rel="noopener noreferrer">亚马逊美食评论数据集。</a></p><h3 id="获取嵌入" tabindex="-1"><a class="header-anchor" href="#获取嵌入"><span>获取嵌入</span></a></h3><p>该数据集包含截至 2012 年 10 月亚马逊用户留下的总共 568,454 条食品评论。我们将使用 1,000 条最新评论的子集用于说明目的。评论是英文的，往往是正面的或负面的。每条评论都有一个 ProductId、UserId、Score、评论标题（摘要）和评论正文（文本）。例如：</p><table><thead><tr><th style="text-align:left;">产品编号</th><th style="text-align:left;">用户身份</th><th style="text-align:left;">分数</th><th style="text-align:left;">概括</th><th style="text-align:left;">文本</th></tr></thead><tbody><tr><td style="text-align:left;">B001E4KFG0</td><td style="text-align:left;">A3SGXH7AUHU8GW</td><td style="text-align:left;">5个</td><td style="text-align:left;">优质狗粮</td><td style="text-align:left;">我买了好几个活力罐头...</td></tr><tr><td style="text-align:left;">B00813GRG4</td><td style="text-align:left;">A1D87F6ZCVE5NK</td><td style="text-align:left;">1个</td><td style="text-align:left;">不像宣传的那样</td><td style="text-align:left;">产品到达时标记为 Jumbo Salted Peanut...</td></tr></tbody></table><p>我们会将评论摘要和评论文本合并为一个组合文本。该模型将对该组合文本进行编码并输出单个向量嵌入。</p><p><a href="https://github.com/openai/openai-cookbook/blob/main/examples/Obtain_dataset.ipynb" target="_blank" rel="noopener noreferrer">获取数据集.ipynb</a></p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">def</span> <span class="token function">get_embedding</span><span class="token punctuation">(</span>text<span class="token punctuation">,</span> model<span class="token operator">=</span><span class="token string">&quot;text-embedding-ada-002&quot;</span><span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">   text <span class="token operator">=</span> text<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">&quot;\\n&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot; &quot;</span><span class="token punctuation">)</span></span>
<span class="line">   <span class="token keyword">return</span> openai<span class="token punctuation">.</span>Embedding<span class="token punctuation">.</span>create<span class="token punctuation">(</span><span class="token builtin">input</span> <span class="token operator">=</span> <span class="token punctuation">[</span>text<span class="token punctuation">]</span><span class="token punctuation">,</span> model<span class="token operator">=</span>model<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">&#39;data&#39;</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">&#39;embedding&#39;</span><span class="token punctuation">]</span></span>
<span class="line"> </span>
<span class="line">df<span class="token punctuation">[</span><span class="token string">&#39;ada_embedding&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">.</span>combined<span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> get_embedding<span class="token punctuation">(</span>x<span class="token punctuation">,</span> model<span class="token operator">=</span><span class="token string">&#39;text-embedding-ada-002&#39;</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line">df<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span><span class="token string">&#39;output/embedded_1k_reviews.csv&#39;</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>要从保存的文件中加载数据，您可以运行以下命令：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd</span>
<span class="line"> </span>
<span class="line">df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">&#39;output/embedded_1k_reviews.csv&#39;</span><span class="token punctuation">)</span></span>
<span class="line">df<span class="token punctuation">[</span><span class="token string">&#39;ada_embedding&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">.</span>ada_embedding<span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span><span class="token builtin">eval</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><details class="hint-container details"><summary>二维数据可视化</summary><p><a href="https://github.com/openai/openai-cookbook/blob/main/examples/Visualizing_embeddings_in_2D.ipynb" target="_blank" rel="noopener noreferrer">Visualizing_embeddings_in_2D.ipynb</a></p><p>嵌入的大小随底层模型的复杂性而变化。为了可视化这种高维数据，我们使用 t-SNE 算法将数据转换为二维。</p><p>我们根据评论者给出的星级评分为各个评论着色：</p><ul><li>1星：红色</li><li>2星：深橙色</li><li>3星：黄金</li><li>4星：绿松石</li><li>5星：深绿色</li></ul><img src="https://cdn.openai.com/API/docs/images/embeddings-tsne.png" alt="使用 t-SNE 以语言可视化的亚马逊评分" style="zoom:50%;"><p>可视化似乎产生了大约 3 个集群，其中一个集群的评论大多是负面的。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd</span>
<span class="line"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>manifold <span class="token keyword">import</span> TSNE</span>
<span class="line"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt</span>
<span class="line"><span class="token keyword">import</span> matplotlib</span>
<span class="line"> </span>
<span class="line">df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">&#39;output/embedded_1k_reviews.csv&#39;</span><span class="token punctuation">)</span></span>
<span class="line">matrix <span class="token operator">=</span> df<span class="token punctuation">.</span>ada_embedding<span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span><span class="token builtin">eval</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to_list<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"> </span>
<span class="line"><span class="token comment"># Create a t-SNE model and transform the data</span></span>
<span class="line">tsne <span class="token operator">=</span> TSNE<span class="token punctuation">(</span>n_components<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> perplexity<span class="token operator">=</span><span class="token number">15</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">,</span> init<span class="token operator">=</span><span class="token string">&#39;random&#39;</span><span class="token punctuation">,</span> learning_rate<span class="token operator">=</span><span class="token number">200</span><span class="token punctuation">)</span></span>
<span class="line">vis_dims <span class="token operator">=</span> tsne<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>matrix<span class="token punctuation">)</span></span>
<span class="line"> </span>
<span class="line">colors <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&quot;red&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;darkorange&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;gold&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;turquiose&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;darkgreen&quot;</span><span class="token punctuation">]</span></span>
<span class="line">x <span class="token operator">=</span> <span class="token punctuation">[</span>x <span class="token keyword">for</span> x<span class="token punctuation">,</span>y <span class="token keyword">in</span> vis_dims<span class="token punctuation">]</span></span>
<span class="line">y <span class="token operator">=</span> <span class="token punctuation">[</span>y <span class="token keyword">for</span> x<span class="token punctuation">,</span>y <span class="token keyword">in</span> vis_dims<span class="token punctuation">]</span></span>
<span class="line">color_indices <span class="token operator">=</span> df<span class="token punctuation">.</span>Score<span class="token punctuation">.</span>values <span class="token operator">-</span> <span class="token number">1</span></span>
<span class="line"> </span>
<span class="line">colormap <span class="token operator">=</span> matplotlib<span class="token punctuation">.</span>colors<span class="token punctuation">.</span>ListedColormap<span class="token punctuation">(</span>colors<span class="token punctuation">)</span></span>
<span class="line">plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> c<span class="token operator">=</span>color_indices<span class="token punctuation">,</span> cmap<span class="token operator">=</span>colormap<span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">)</span></span>
<span class="line">plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">&quot;Amazon ratings visualized in language using t-SNE&quot;</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></details><details class="hint-container details"><summary>嵌入作为 ML 算法的文本特征编码器</summary><p><a href="https://github.com/openai/openai-cookbook/blob/main/examples/Regression_using_embeddings.ipynb" target="_blank" rel="noopener noreferrer">回归_使用_embeddings.ipynb</a></p><p>嵌入可以用作机器学习模型中的通用自由文本特征编码器。如果一些相关输入是自由文本，则合并嵌入将提高任何机器学习模型的性能。嵌入也可以用作 ML 模型中的分类特征编码器。如果分类变量的名称有意义且数量众多，例如职位名称，那么这会增加最大的价值。对于此任务，相似性嵌入通常比搜索嵌入表现更好。</p><p>我们观察到，通常嵌入表示非常丰富且信息密集。例如，使用 SVD 或 PCA 降低输入的维度，即使降低 10%，通常也会导致特定任务的下游性能变差。</p><p>此代码将数据拆分为训练集和测试集，将由以下两个用例使用，即回归和分类。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"></span>
<span class="line"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split</span>
<span class="line"> </span>
<span class="line">X_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span></span>
<span class="line">    <span class="token builtin">list</span><span class="token punctuation">(</span>df<span class="token punctuation">.</span>ada_embedding<span class="token punctuation">.</span>values<span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line">    df<span class="token punctuation">.</span>Score<span class="token punctuation">,</span></span>
<span class="line">    test_size <span class="token operator">=</span> <span class="token number">0.2</span><span class="token punctuation">,</span></span>
<span class="line">    random_state<span class="token operator">=</span><span class="token number">42</span></span>
<span class="line"><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></details><details class="hint-container details"><summary>使用嵌入特征进行回归</summary><p>嵌入提供了一种预测数值的优雅方法。在此示例中，我们根据评论文本预测评论者的星级。因为嵌入中包含的语义信息很高，所以即使评论很少，预测也不错。</p><p>我们假设分数是 1 到 5 之间的连续变量，并允许算法预测任何浮点值。ML 算法最小化预测值与真实分数的距离，并实现 0.39 的平均绝对误差，这意味着平均预测偏差不到半星。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"></span>
<span class="line"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>ensemble <span class="token keyword">import</span> RandomForestRegressor</span>
<span class="line"> </span>
<span class="line">rfr <span class="token operator">=</span> RandomForestRegressor<span class="token punctuation">(</span>n_estimators<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span></span>
<span class="line">rfr<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span></span>
<span class="line">preds <span class="token operator">=</span> rfr<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></details><details class="hint-container details"><summary>使用嵌入特征进行分类</summary><p><a href="https://github.com/openai/openai-cookbook/blob/main/examples/Classification_using_embeddings.ipynb" target="_blank" rel="noopener noreferrer">Classification_using_embeddings.ipynb</a></p><p>这一次，我们不再让算法预测 1 到 5 之间的任何值，而是尝试将评论的确切星数分类为 5 个桶，范围从 1 到 5 星。</p><p>训练后，该模型学习预测 1 星和 5 星评论比更细微的评论（2-4 星）更好，这可能是由于更极端的情绪表达。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"></span>
<span class="line"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>ensemble <span class="token keyword">import</span> RandomForestClassifier</span>
<span class="line"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> classification_report<span class="token punctuation">,</span> accuracy_score</span>
<span class="line"> </span>
<span class="line">clf <span class="token operator">=</span> RandomForestClassifier<span class="token punctuation">(</span>n_estimators<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span></span>
<span class="line">clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span></span>
<span class="line">preds <span class="token operator">=</span> clf<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></details><details class="hint-container details"><summary>零样本分类</summary><p><a href="https://github.com/openai/openai-cookbook/blob/main/examples/Zero-shot_classification_with_embeddings.ipynb" target="_blank" rel="noopener noreferrer">零射分类_with_embeddings.ipynb</a></p><p>我们可以在没有任何标记训练数据的情况下使用嵌入进行零镜头分类。对于每个类，我们嵌入类名或类的简短描述。为了以零样本方式对一些新文本进行分类，我们将其嵌入与所有类嵌入进行比较，并预测具有最高相似度的类。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"></span>
<span class="line"><span class="token keyword">from</span> openai<span class="token punctuation">.</span>embeddings_utils <span class="token keyword">import</span> cosine_similarity<span class="token punctuation">,</span> get_embedding</span>
<span class="line"> </span>
<span class="line">df<span class="token operator">=</span> df<span class="token punctuation">[</span>df<span class="token punctuation">.</span>Score<span class="token operator">!=</span><span class="token number">3</span><span class="token punctuation">]</span></span>
<span class="line">df<span class="token punctuation">[</span><span class="token string">&#39;sentiment&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">.</span>Score<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token string">&#39;negative&#39;</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span><span class="token string">&#39;negative&#39;</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">:</span><span class="token string">&#39;positive&#39;</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">:</span><span class="token string">&#39;positive&#39;</span><span class="token punctuation">}</span><span class="token punctuation">)</span></span>
<span class="line"> </span>
<span class="line">labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&#39;negative&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;positive&#39;</span><span class="token punctuation">]</span></span>
<span class="line">label_embeddings <span class="token operator">=</span> <span class="token punctuation">[</span>get_embedding<span class="token punctuation">(</span>label<span class="token punctuation">,</span> model<span class="token operator">=</span>model<span class="token punctuation">)</span> <span class="token keyword">for</span> label <span class="token keyword">in</span> labels<span class="token punctuation">]</span></span>
<span class="line"> </span>
<span class="line"><span class="token keyword">def</span> <span class="token function">label_score</span><span class="token punctuation">(</span>review_embedding<span class="token punctuation">,</span> label_embeddings<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">   <span class="token keyword">return</span> cosine_similarity<span class="token punctuation">(</span>review_embedding<span class="token punctuation">,</span> label_embeddings<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span> cosine_similarity<span class="token punctuation">(</span>review_embedding<span class="token punctuation">,</span> label_embeddings<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line"> </span>
<span class="line">prediction <span class="token operator">=</span> <span class="token string">&#39;positive&#39;</span> <span class="token keyword">if</span> label_score<span class="token punctuation">(</span><span class="token string">&#39;Sample Review&#39;</span><span class="token punctuation">,</span> label_embeddings<span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">0</span> <span class="token keyword">else</span> <span class="token string">&#39;negative&#39;</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></details><details class="hint-container details"><summary>获取用于冷启动推荐的用户和产品嵌入</summary><p><a href="https://github.com/openai/openai-cookbook/blob/main/examples/User_and_product_embeddings.ipynb" target="_blank" rel="noopener noreferrer">User_and_product_embeddings.ipynb</a></p><p>我们可以通过对他们的所有评论进行平均来获得用户嵌入。同样，我们可以通过对有关该产品的所有评论进行平均来获得产品嵌入。为了展示这种方法的实用性，我们使用 50k 评论的子集来覆盖每个用户和每个产品的更多评论。</p><p>我们在单独的测试集上评估这些嵌入的有用性，我们将用户和产品嵌入的相似性绘制为评分的函数。有趣的是，基于这种方法，甚至在用户收到产品之前，我们就可以比随机预测更好地预测他们是否喜欢该产品。</p><img src="https://cdn.openai.com/API/docs/images/embeddings-boxplot.png" alt="按得分分组的箱线图" style="zoom:50%;"><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line">user_embeddings <span class="token operator">=</span> df<span class="token punctuation">.</span>groupby<span class="token punctuation">(</span><span class="token string">&#39;UserId&#39;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>ada_embedding<span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>mean<span class="token punctuation">)</span></span>
<span class="line">prod_embeddings <span class="token operator">=</span> df<span class="token punctuation">.</span>groupby<span class="token punctuation">(</span><span class="token string">&#39;ProductId&#39;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>ada_embedding<span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>mean<span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div></details><details class="hint-container details"><summary>聚类</summary><p><a href="https://github.com/openai/openai-cookbook/blob/main/examples/Clustering.ipynb" target="_blank" rel="noopener noreferrer">聚类.ipynb</a></p><p>聚类是理解大量文本数据的一种方式。嵌入对于这项任务很有用，因为它们提供了每个文本的语义上有意义的向量表示。因此，以一种无监督的方式，聚类将揭示我们数据集中隐藏的分组。</p><p>在这个例子中，我们发现了四个不同的集群：一个专注于狗食，一个专注于负面评论，两个专注于正面评论。</p><img src="https://cdn.openai.com/API/docs/images/embeddings-cluster.png" alt="使用 t-SNE 以 2d 语言可视化识别的集群" style="zoom:50%;"><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"></span>
<span class="line"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np</span>
<span class="line"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>cluster <span class="token keyword">import</span> KMeans</span>
<span class="line"> </span>
<span class="line">matrix <span class="token operator">=</span> np<span class="token punctuation">.</span>vstack<span class="token punctuation">(</span>df<span class="token punctuation">.</span>ada_embedding<span class="token punctuation">.</span>values<span class="token punctuation">)</span></span>
<span class="line">n_clusters <span class="token operator">=</span> <span class="token number">4</span></span>
<span class="line"> </span>
<span class="line">kmeans <span class="token operator">=</span> KMeans<span class="token punctuation">(</span>n_clusters <span class="token operator">=</span> n_clusters<span class="token punctuation">,</span> init<span class="token operator">=</span><span class="token string">&#39;k-means++&#39;</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span></span>
<span class="line">kmeans<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>matrix<span class="token punctuation">)</span></span>
<span class="line">df<span class="token punctuation">[</span><span class="token string">&#39;Cluster&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> kmeans<span class="token punctuation">.</span>labels_</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></details><details class="hint-container details"><summary>使用嵌入的文本搜索</summary><p><a href="https://github.com/openai/openai-cookbook/blob/main/examples/Semantic_text_search_using_embeddings.ipynb" target="_blank" rel="noopener noreferrer">Semantic_text_search_using_embeddings.ipynb</a></p><p>为了检索最相关的文档，我们使用查询的嵌入向量与每个文档之间的余弦相似度，并返回得分最高的文档。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"></span>
<span class="line"><span class="token keyword">from</span> openai<span class="token punctuation">.</span>embeddings_utils <span class="token keyword">import</span> get_embedding<span class="token punctuation">,</span> cosine_similarity</span>
<span class="line"> </span>
<span class="line"><span class="token keyword">def</span> <span class="token function">search_reviews</span><span class="token punctuation">(</span>df<span class="token punctuation">,</span> product_description<span class="token punctuation">,</span> n<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> pprint<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">   embedding <span class="token operator">=</span> get_embedding<span class="token punctuation">(</span>product_description<span class="token punctuation">,</span> model<span class="token operator">=</span><span class="token string">&#39;text-embedding-ada-002&#39;</span><span class="token punctuation">)</span></span>
<span class="line">   df<span class="token punctuation">[</span><span class="token string">&#39;similarities&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">.</span>ada_embedding<span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> cosine_similarity<span class="token punctuation">(</span>x<span class="token punctuation">,</span> embedding<span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line">   res <span class="token operator">=</span> df<span class="token punctuation">.</span>sort_values<span class="token punctuation">(</span><span class="token string">&#39;similarities&#39;</span><span class="token punctuation">,</span> ascending<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">.</span>head<span class="token punctuation">(</span>n<span class="token punctuation">)</span></span>
<span class="line">   <span class="token keyword">return</span> res</span>
<span class="line"> </span>
<span class="line">res <span class="token operator">=</span> search_reviews<span class="token punctuation">(</span>df<span class="token punctuation">,</span> <span class="token string">&#39;delicious beans&#39;</span><span class="token punctuation">,</span> n<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></details><details class="hint-container details"><summary>使用嵌入的代码搜索</summary><p><a href="https://github.com/openai/openai-cookbook/blob/main/examples/Code_search.ipynb" target="_blank" rel="noopener noreferrer">代码搜索.ipynb</a></p><p>代码搜索的工作方式类似于基于嵌入的文本搜索。我们提供了一种从给定存储库中的所有 Python 文件中提取 Python 函数的方法。然后每个函数都由<code>text-embedding-ada-002</code>模型索引。</p><p>为了执行代码搜索，我们使用相同的模型将查询嵌入到自然语言中。然后我们计算结果查询嵌入和每个函数嵌入之间的余弦相似度。最高的余弦相似度结果是最相关的。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"></span>
<span class="line"><span class="token keyword">from</span> openai<span class="token punctuation">.</span>embeddings_utils <span class="token keyword">import</span> get_embedding<span class="token punctuation">,</span> cosine_similarity</span>
<span class="line"> </span>
<span class="line">df<span class="token punctuation">[</span><span class="token string">&#39;code_embedding&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">&#39;code&#39;</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> get_embedding<span class="token punctuation">(</span>x<span class="token punctuation">,</span> model<span class="token operator">=</span><span class="token string">&#39;text-embedding-ada-002&#39;</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"> </span>
<span class="line"><span class="token keyword">def</span> <span class="token function">search_functions</span><span class="token punctuation">(</span>df<span class="token punctuation">,</span> code_query<span class="token punctuation">,</span> n<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> pprint<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> n_lines<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">   embedding <span class="token operator">=</span> get_embedding<span class="token punctuation">(</span>code_query<span class="token punctuation">,</span> model<span class="token operator">=</span><span class="token string">&#39;text-embedding-ada-002&#39;</span><span class="token punctuation">)</span></span>
<span class="line">   df<span class="token punctuation">[</span><span class="token string">&#39;similarities&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">.</span>code_embedding<span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> cosine_similarity<span class="token punctuation">(</span>x<span class="token punctuation">,</span> embedding<span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"> </span>
<span class="line">   res <span class="token operator">=</span> df<span class="token punctuation">.</span>sort_values<span class="token punctuation">(</span><span class="token string">&#39;similarities&#39;</span><span class="token punctuation">,</span> ascending<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">.</span>head<span class="token punctuation">(</span>n<span class="token punctuation">)</span></span>
<span class="line">   <span class="token keyword">return</span> res</span>
<span class="line">res <span class="token operator">=</span> search_functions<span class="token punctuation">(</span>df<span class="token punctuation">,</span> <span class="token string">&#39;Completions API tests&#39;</span><span class="token punctuation">,</span> n<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></details><details class="hint-container details"><summary>使用嵌入的推荐</summary><p><a href="https://github.com/openai/openai-cookbook/blob/main/examples/Recommendation_using_embeddings.ipynb" target="_blank" rel="noopener noreferrer">Recommendation_using_embeddings.ipynb</a></p><p>因为嵌入向量之间的距离越短表示相似度越高，嵌入可用于推荐。</p><p>下面，我们说明了一个基本的推荐系统。它接受一个字符串列表和一个“源”字符串，计算它们的嵌入，然后返回字符串的排名，从最相似到最不相似。作为一个具体示例，下面链接的笔记本将此函数的一个版本应用于<a href="http://groups.di.unipi.it/~gulli/AG_corpus_of_news_articles.html" target="_blank" rel="noopener noreferrer">AG 新闻数据集</a>（采样到 2,000 篇新闻文章描述）以返回与任何给定源文章最相似的前 5 篇文章。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"></span>
<span class="line"><span class="token keyword">def</span> <span class="token function">recommendations_from_strings</span><span class="token punctuation">(</span></span>
<span class="line">   strings<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">   index_of_source_string<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span></span>
<span class="line">   model<span class="token operator">=</span><span class="token string">&quot;text-embedding-ada-002&quot;</span><span class="token punctuation">,</span></span>
<span class="line"><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> List<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">:</span></span>
<span class="line">   <span class="token triple-quoted-string string">&quot;&quot;&quot;Return nearest neighbors of a given string.&quot;&quot;&quot;</span></span>
<span class="line"></span>
<span class="line">   <span class="token comment"># get embeddings for all strings</span></span>
<span class="line">   embeddings <span class="token operator">=</span> <span class="token punctuation">[</span>embedding_from_string<span class="token punctuation">(</span>string<span class="token punctuation">,</span> model<span class="token operator">=</span>model<span class="token punctuation">)</span> <span class="token keyword">for</span> string <span class="token keyword">in</span> strings<span class="token punctuation">]</span></span>
<span class="line">   </span>
<span class="line">   <span class="token comment"># get the embedding of the source string</span></span>
<span class="line">   query_embedding <span class="token operator">=</span> embeddings<span class="token punctuation">[</span>index_of_source_string<span class="token punctuation">]</span></span>
<span class="line">   </span>
<span class="line">   <span class="token comment"># get distances between the source embedding and other embeddings (function from embeddings_utils.py)</span></span>
<span class="line">   distances <span class="token operator">=</span> distances_from_embeddings<span class="token punctuation">(</span>query_embedding<span class="token punctuation">,</span> embeddings<span class="token punctuation">,</span> distance_metric<span class="token operator">=</span><span class="token string">&quot;cosine&quot;</span><span class="token punctuation">)</span></span>
<span class="line">   </span>
<span class="line">   <span class="token comment"># get indices of nearest neighbors (function from embeddings_utils.py)</span></span>
<span class="line">   indices_of_nearest_neighbors <span class="token operator">=</span> indices_of_nearest_neighbors_from_distances<span class="token punctuation">(</span>distances<span class="token punctuation">)</span></span>
<span class="line">   <span class="token keyword">return</span> indices_of_nearest_neighbors</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></details><h2 id="局限性和风险" tabindex="-1"><a class="header-anchor" href="#局限性和风险"><span>局限性和风险</span></a></h2><p>我们的嵌入模型可能不可靠或在某些情况下会带来社会风险，并且在没有缓解措施的情况下可能会造成伤害。</p><h3 id="社会偏见" tabindex="-1"><a class="header-anchor" href="#社会偏见"><span>社会偏见</span></a></h3>`,47)),e(a,{ctt:"局限性：模型对社会偏见进行编码，例如通过对某些群体的刻板印象或负面情绪。"}),n[1]||(n[1]=s('<p>我们通过运行 SEAT（<a href="https://arxiv.org/abs/1903.10561" target="_blank" rel="noopener noreferrer">May 等人，2019 年</a>）和 Winogender（Rudinger<a href="https://arxiv.org/abs/1804.09301" target="_blank" rel="noopener noreferrer">等人，2018 年</a>）基准测试发现了模型中存在偏差的证据。这些基准一起包含 7 个测试，用于衡量模型在应用于性别名称、区域名称和某些刻板印象时是否包含隐性偏见。</p><p>例如，我们发现，与非裔美国人的名字相比，我们的模型更强烈地将 (a) 欧裔美国人的名字与积极情绪联系起来，以及 (b) 对黑人女性的负面刻板印象。</p><p>这些基准在几个方面存在局限性：(a) 它们可能无法推广到您的特定用例，以及 (b) 它们仅测试极小部分可能的社会偏见。</p><p><strong>这些测试是初步的，我们建议针对您的特定用例运行测试</strong>。这些结果应被视为该现象存在的证据，而不是对您的用例的明确描述。请参阅我们的<a href="/start/%E4%BD%BF%E7%94%A8%E6%94%BF%E7%AD%96">使用政策</a>以获取更多详细信息和指导。</p><p>如果您有任何问题，请<a href="https://help.openai.com/en/" target="_blank" rel="noopener noreferrer">通过聊天联系我们的支持团队；</a>我们很乐意就此提供建议。</p><p><a href="https://platform.openai.com/docs/guides/embeddings/blindness-to-recent-events" target="_blank" rel="noopener noreferrer">对最近发生的事件视而不见</a></p>',6)),e(a,{ctt:"局限性：模型缺乏对 2020 年 8 月之后发生的事件的了解。"}),n[2]||(n[2]=s(`<p>我们的模型在包含 8/2020 之前真实世界事件的一些信息的数据集上进行训练。如果你依赖于代表最近事件的模型，那么它们可能表现不佳。</p><h3 id="经常问的问题" tabindex="-1"><a class="header-anchor" href="#经常问的问题"><span>经常问的问题</span></a></h3><h4 id="在嵌入字符串之前-如何知道它有多少个标记" tabindex="-1"><a class="header-anchor" href="#在嵌入字符串之前-如何知道它有多少个标记"><span>在嵌入字符串之前，如何知道它有多少个标记？</span></a></h4><p>在 Python 中，您可以使用 OpenAI 的标记器将字符串拆分为标记<a href="https://github.com/openai/tiktoken" target="_blank" rel="noopener noreferrer"><code>tiktoken</code></a>。</p><p>示例代码：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">import</span> tiktoken</span>
<span class="line"></span>
<span class="line"><span class="token keyword">def</span> <span class="token function">num_tokens_from_string</span><span class="token punctuation">(</span>string<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> encoding_name<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">int</span><span class="token punctuation">:</span></span>
<span class="line">    <span class="token triple-quoted-string string">&quot;&quot;&quot;Returns the number of tokens in a text string.&quot;&quot;&quot;</span></span>
<span class="line">    encoding <span class="token operator">=</span> tiktoken<span class="token punctuation">.</span>get_encoding<span class="token punctuation">(</span>encoding_name<span class="token punctuation">)</span></span>
<span class="line">    num_tokens <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>encoding<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>string<span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line">    <span class="token keyword">return</span> num_tokens</span>
<span class="line"></span>
<span class="line">num_tokens_from_string<span class="token punctuation">(</span><span class="token string">&quot;tiktoken is great!&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;cl100k_base&quot;</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>对于像 的第二代嵌入模型<code>text-embedding-ada-002</code>，请使用<code>cl100k_base</code>编码。</p><p>更多详细信息和示例代码在 OpenAI Cookbook 指南<a href="https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb" target="_blank" rel="noopener noreferrer">how to count tokens with tiktoken</a>中。</p><h4 id="如何快速检索-k-个最近的嵌入向量" tabindex="-1"><a class="header-anchor" href="#如何快速检索-k-个最近的嵌入向量"><span>如何快速检索 K 个最近的嵌入向量？</span></a></h4><p>为了快速搜索多个矢量，我们建议使用矢量数据库。您可以在 GitHub 上的<a href="https://github.com/openai/openai-cookbook/tree/main/examples/vector_databases" target="_blank" rel="noopener noreferrer"> Cookbook</a>中找到使用矢量数据库和 OpenAI API 的示例。</p><p>矢量数据库选项包括：</p><ul><li><a href="https://www.pinecone.io/" target="_blank" rel="noopener noreferrer">Pinecone</a>，一个完全托管的矢量数据库</li><li><a href="https://weaviate.io/" target="_blank" rel="noopener noreferrer">Weaviate</a>，一个开源矢量搜索引擎</li><li><a href="https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/" target="_blank" rel="noopener noreferrer">Faiss</a> , Facebook 的矢量搜索算法</li><li><a href="https://redis.com/blog/rediscover-redis-for-vector-similarity-search/" target="_blank" rel="noopener noreferrer">Redis</a>作为矢量数据库</li><li><a href="https://qdrant.tech/" target="_blank" rel="noopener noreferrer">Qdrant</a>，一个矢量搜索引擎</li><li><a href="https://typesense.org/docs/0.24.0/api/vector-search.html" target="_blank" rel="noopener noreferrer">Typesense</a>，开源搜索引擎，带有矢量搜索</li></ul><h4 id="我应该使用哪个距离函数" tabindex="-1"><a class="header-anchor" href="#我应该使用哪个距离函数"><span>我应该使用哪个距离函数？</span></a></h4><p>我们推荐<a href="https://en.wikipedia.org/wiki/Cosine_similarity" target="_blank" rel="noopener noreferrer">余弦相似度</a>。距离函数的选择通常无关紧要。</p><p>OpenAI 嵌入被归一化为长度 1，这意味着：</p><ul><li>仅使用点积可以稍微更快地计算余弦相似度</li><li>余弦相似度和欧几里德距离将导致相同的排名</li></ul>`,16))])}const u=t(i,[["render",c],["__file","嵌入.html.vue"]]),k=JSON.parse('{"path":"/guides/%E5%B5%8C%E5%85%A5.html","title":"嵌入","lang":"zh-cn","frontmatter":{},"headers":[{"level":1,"title":"嵌入","slug":"嵌入","link":"#嵌入","children":[{"level":2,"title":"什么是嵌入？","slug":"什么是嵌入","link":"#什么是嵌入","children":[{"level":3,"title":"如何获得嵌入","slug":"如何获得嵌入","link":"#如何获得嵌入","children":[]},{"level":3,"title":"嵌入模型","slug":"嵌入模型","link":"#嵌入模型","children":[]},{"level":3,"title":"二代模型","slug":"二代模型","link":"#二代模型","children":[]}]},{"level":2,"title":"用例","slug":"用例","link":"#用例","children":[{"level":3,"title":"获取嵌入","slug":"获取嵌入","link":"#获取嵌入","children":[]}]},{"level":2,"title":"局限性和风险","slug":"局限性和风险","link":"#局限性和风险","children":[{"level":3,"title":"社会偏见","slug":"社会偏见","link":"#社会偏见","children":[]},{"level":3,"title":"经常问的问题","slug":"经常问的问题","link":"#经常问的问题","children":[]}]}]}],"git":{},"filePathRelative":"guides/嵌入.md"}');export{u as comp,k as data};
