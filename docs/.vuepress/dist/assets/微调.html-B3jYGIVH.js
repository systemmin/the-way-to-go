import{_ as s,c as a,a as e,o as t}from"./app-DtITwm2S.js";const p={};function o(l,n){return t(),a("div",null,n[0]||(n[0]=[e(`<h1 id="微调" tabindex="-1"><a class="header-anchor" href="#微调"><span><a href="https://platform.openai.com/docs/guides/fine-tuning/fine-tuning" target="_blank" rel="noopener noreferrer">微调</a></span></a></h1><p>了解如何为您的应用程序定制模型。</p><h2 id="介绍" tabindex="-1"><a class="header-anchor" href="#介绍"><span>介绍</span></a></h2><p>通过提供以下内容，微调可让您从 API 提供的模型中获得更多收益：</p><ol><li>比即时设计更高质量的结果</li><li>能够训练比提示中更多的例子</li><li>由于更短的提示而节省了标记</li><li>更低的延迟请求</li></ol><p>GPT-3 已经在来自开放互联网的大量文本上进行了预训练。当给出仅包含几个示例的提示时，它通常可以凭直觉判断出您要执行的任务并生成合理的完成。这通常称为“小样本学习”。</p><p>微调通过训练比提示中更多的示例来改进小样本学习，让您在大量任务中取得更好的结果。**对模型进行微调后，您将不再需要在提示中提供示例。**这样可以节省成本并实现更低延迟的请求。</p><p>在高层次上，微调涉及以下步骤：</p><ol><li>准备和上传训练数据</li><li>训练新的微调模型</li><li>使用您的微调模型</li></ol><p>请访问我们的<a href="https://openai.com/api/pricing" target="_blank" rel="noopener noreferrer">定价页面</a>，详细了解微调模型训练和使用的收费方式。</p><p><strong>哪些模型可以微调</strong>？</p><p>微调目前仅适用于以下基础模型：<code>davinci</code>、<code>curie</code>、<code>babbage</code>和<code>ada</code>。这些是原始模型，在训练后没有任何说明（<code>text-davinci-003</code>例如）。您还可以<a href="https://platform.openai.com/docs/guides/fine-tuning/continue-fine-tuning-from-a-fine-tuned-model" target="_blank" rel="noopener noreferrer">继续微调微调模型</a>以添加其他数据，而无需从头开始。</p><p><strong>安装</strong></p><p>我们建议使用我们的 OpenAI 命令行界面 (CLI)。要安装这个，运行</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line">pip <span class="token function">install</span> <span class="token parameter variable">--upgrade</span> openai</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>（以下说明适用于<strong>0.9.4</strong>及更高版本。此外，OpenAI CLI 需要 python 3。）</p><p><code>OPENAI_API_KEY</code>通过将以下行添加到您的 shell 初始化脚本（例如 .bashrc、zshrc 等）或在微调命令之前的命令行中运行它来设置您的环境变量：</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line"><span class="token builtin class-name">export</span> <span class="token assign-left variable">OPENAI_API_KEY</span><span class="token operator">=</span><span class="token string">&quot;&lt;OPENAI_API_KEY&gt;&quot;</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h2 id="准备训练数据" tabindex="-1"><a class="header-anchor" href="#准备训练数据"><span>准备训练数据</span></a></h2><p>训练数据是你如何教 GPT-3 你想让它说什么。</p><p>您的数据必须是<a href="https://jsonlines.org/" target="_blank" rel="noopener noreferrer">JSONL</a>文档，其中每一行都是一个提示完成对，对应于一个训练示例。您可以使用我们的<a href="https://platform.openai.com/docs/guides/fine-tuning/cli-data-preparation-tool" target="_blank" rel="noopener noreferrer">CLI 数据准备工具</a>轻松地将您的数据转换成这种文件格式。</p><div class="language-json line-numbers-mode" data-highlighter="prismjs" data-ext="json" data-title="json"><pre><code><span class="line"><span class="token punctuation">{</span><span class="token property">&quot;prompt&quot;</span><span class="token operator">:</span> <span class="token string">&quot;&lt;prompt text&gt;&quot;</span><span class="token punctuation">,</span> <span class="token property">&quot;completion&quot;</span><span class="token operator">:</span> <span class="token string">&quot;&lt;ideal generated text&gt;&quot;</span><span class="token punctuation">}</span></span>
<span class="line"><span class="token punctuation">{</span><span class="token property">&quot;prompt&quot;</span><span class="token operator">:</span> <span class="token string">&quot;&lt;prompt text&gt;&quot;</span><span class="token punctuation">,</span> <span class="token property">&quot;completion&quot;</span><span class="token operator">:</span> <span class="token string">&quot;&lt;ideal generated text&gt;&quot;</span><span class="token punctuation">}</span></span>
<span class="line"><span class="token punctuation">{</span><span class="token property">&quot;prompt&quot;</span><span class="token operator">:</span> <span class="token string">&quot;&lt;prompt text&gt;&quot;</span><span class="token punctuation">,</span> <span class="token property">&quot;completion&quot;</span><span class="token operator">:</span> <span class="token string">&quot;&lt;ideal generated text&gt;&quot;</span><span class="token punctuation">}</span></span>
<span class="line">...</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>设计用于微调的提示和补全不同于设计用于我们的基本模型（Davinci、Curie、Babbage、Ada）的提示。特别是，虽然基础模型的提示通常包含多个示例（“小样本学习”），但对于微调，每个训练示例通常包含一个输入示例及其相关输出，无需给出详细说明或在同一提示中包含多个示例。</p><p><strong>有关如何为各种任务准备训练数据的更多详细指导，请参阅我们的<a href="https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset" target="_blank" rel="noopener noreferrer">准备数据集</a>指南。</strong></p><p>您拥有的训练示例越多越好。我们建议至少有几百个示例。一般来说，我们发现数据集大小每增加一倍都会导致模型质量线性增加。</p><p><strong>CLI数据准备工具</strong></p><p>我们开发了一个工具来验证、提供建议和重新格式化您的数据：</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line">openai tools fine_tunes.prepare_data <span class="token parameter variable">-f</span> <span class="token operator">&lt;</span>LOCAL_FILE<span class="token operator">&gt;</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>此工具接受不同的格式，唯一的要求是它们包含提示和完成列/键。您可以传递<strong>CSV、TSV、XLSX、JSON</strong>或<strong>JSONL</strong>文件，它会在指导您完成建议的更改过程后将输出保存到 JSONL 文件中以备微调。</p><p><strong>创建微调模型</strong></p><p>以下假设您已经按照<a href="https://platform.openai.com/docs/guides/fine-tuning/prepare-training-data" target="_blank" rel="noopener noreferrer">上述说明</a>准备了训练数据。</p><p>使用 OpenAI CLI 开始微调工作：</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line">openai api fine_tunes.create <span class="token parameter variable">-t</span> <span class="token operator">&lt;</span>TRAIN_FILE_ID_OR_PATH<span class="token operator">&gt;</span> <span class="token parameter variable">-m</span> <span class="token operator">&lt;</span>BASE_MODEL<span class="token operator">&gt;</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>您从哪里<code>BASE_MODEL</code>开始的基本模型的名称（ada、babbage、curie 或 davinci）。<a href="https://platform.openai.com/docs/guides/fine-tuning/customize-your-model-name" target="_blank" rel="noopener noreferrer">您可以使用后缀参数</a>自定义微调模型的名称。</p><p>运行上面的命令会做几件事：</p><ol><li>使用<a href="https://platform.openai.com/docs/api-reference/files" target="_blank" rel="noopener noreferrer">文件 API</a>上传文件（或使用已经上传的文件）</li><li>创建微调作业</li><li>流式传输事件直到作业完成（这通常需要几分钟，但如果队列中有很多作业或您的数据集很大，则可能需要数小时）</li></ol><p>每个微调工作都从一个默认为 curie 的基本模型开始。模型的选择会影响模型的性能和运行微调模型的成本。您的模型可以是以下之一：<code>ada</code>、<code>babbage</code>、<code>curie</code>或<code>davinci</code>。请访问我们的<a href="https://openai.com/api/pricing/#faq-fine-tuning-pricing-calculation" target="_blank" rel="noopener noreferrer">定价页面</a>，了解有关微调费率的详细信息。</p><p>开始微调作业后，可能需要一些时间才能完成。在我们的系统中，您的工作可能排在其他工作之后，训练我们的模型可能需要几分钟或几小时，具体取决于模型和数据集的大小。如果事件流因任何原因中断，您可以通过运行以下命令恢复它：</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line">openai api fine_tunes.follow <span class="token parameter variable">-i</span> <span class="token operator">&lt;</span>YOUR_FINE_TUNE_JOB_ID<span class="token operator">&gt;</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>工作完成后，它应该显示微调模型的名称。</p><p>除了创建微调作业外，您还可以列出现有作业、检索作业状态或取消作业。</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line"><span class="token comment"># 列出所有创建的微调</span></span>
<span class="line">openai api fine_tunes.list</span>
<span class="line"></span>
<span class="line"><span class="token comment"># 检索微调的状态。结果对象包括</span></span>
<span class="line"><span class="token comment"># 作业状态（可以是挂起、运行、成功或失败之一）</span></span>
<span class="line"><span class="token comment"># 和其他信息</span></span>
<span class="line">openai api fine_tunes.get <span class="token parameter variable">-i</span> <span class="token operator">&lt;</span>YOUR_FINE_TUNE_JOB_ID<span class="token operator">&gt;</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 取消作业</span></span>
<span class="line">openai api fine_tunes.cancel <span class="token parameter variable">-i</span> <span class="token operator">&lt;</span>YOUR_FINE_TUNE_JOB_ID<span class="token operator">&gt;</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>使用微调模型</strong></p><p>当作业成功时，该<code>fine_tuned_model</code>字段将填充模型名称。您现在可以将此模型指定为我们的<a href="https://platform.openai.com/docs/api-reference/completions" target="_blank" rel="noopener noreferrer">Completions API</a>的参数，并使用<a href="https://platform.openai.com/playground" target="_blank" rel="noopener noreferrer">Playground</a>向它发出请求。</p><p>在您的工作首次完成后，您的模型可能需要几分钟时间才能准备好处理请求。如果对您的模型的完成请求超时，可能是因为您的模型仍在加载中。如果发生这种情况，请在几分钟后重试。</p><p>您可以通过将模型名称作为<code>model</code>完成请求的参数传递来开始发出请求：</p><p>OpenAI 命令行界面：</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line">openai api completions.create <span class="token parameter variable">-m</span> <span class="token operator">&lt;</span>FINE_TUNED_MODEL<span class="token operator">&gt;</span> <span class="token parameter variable">-p</span> <span class="token operator">&lt;</span>YOUR_PROMPT<span class="token operator">&gt;</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>cURL：</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line"><span class="token function">curl</span> https://api.openai.com/v1/completions <span class="token punctuation">\\</span></span>
<span class="line">  <span class="token parameter variable">-H</span> <span class="token string">&quot;Authorization: Bearer <span class="token variable">$OPENAI_API_KEY</span>&quot;</span> <span class="token punctuation">\\</span></span>
<span class="line">  <span class="token parameter variable">-H</span> <span class="token string">&quot;Content-Type: application/json&quot;</span> <span class="token punctuation">\\</span></span>
<span class="line">  <span class="token parameter variable">-d</span> <span class="token string">&#39;{&quot;prompt&quot;: YOUR_PROMPT, &quot;model&quot;: FINE_TUNED_MODEL}&#39;</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Python：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">import</span> openai</span>
<span class="line">openai<span class="token punctuation">.</span>Completion<span class="token punctuation">.</span>create<span class="token punctuation">(</span></span>
<span class="line">    model<span class="token operator">=</span>FINE_TUNED_MODEL<span class="token punctuation">,</span></span>
<span class="line">    prompt<span class="token operator">=</span>YOUR_PROMPT<span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Node.js：</p><div class="language-javascript line-numbers-mode" data-highlighter="prismjs" data-ext="js" data-title="js"><pre><code><span class="line"><span class="token keyword">const</span> response <span class="token operator">=</span> <span class="token keyword">await</span> openai<span class="token punctuation">.</span><span class="token function">createCompletion</span><span class="token punctuation">(</span><span class="token punctuation">{</span></span>
<span class="line">  <span class="token literal-property property">model</span><span class="token operator">:</span> <span class="token constant">FINE_TUNED_MODEL</span></span>
<span class="line">  <span class="token literal-property property">prompt</span><span class="token operator">:</span> <span class="token constant">YOUR_PROMPT</span><span class="token punctuation">,</span></span>
<span class="line"><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>您可以继续使用所有其他<a href="https://platform.openai.com/docs/api-reference/completions" target="_blank" rel="noopener noreferrer">补全</a>参数，如<code>temperature</code>、<code>frequency_penalty</code>、<code>presence_penalty</code>等，对这些请求进行微调模型。</p><p><strong>删除微调模型</strong></p><p>要删除微调模型，您必须在您的组织中被指定为“所有者”。</p><p>OpenAI 命令行界面：</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line">openai api models.delete <span class="token parameter variable">-i</span> <span class="token operator">&lt;</span>FINE_TUNED_MODEL<span class="token operator">&gt;</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>cURL：</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line"><span class="token function">curl</span> <span class="token parameter variable">-X</span> <span class="token string">&quot;DELETE&quot;</span> https://api.openai.com/v1/models/<span class="token operator">&lt;</span>FINE_TUNED_MODEL<span class="token operator">&gt;</span> <span class="token punctuation">\\</span></span>
<span class="line">  <span class="token parameter variable">-H</span> <span class="token string">&quot;Authorization: Bearer <span class="token variable">$OPENAI_API_KEY</span>&quot;</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p>Python：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">import</span> openai</span>
<span class="line">openai<span class="token punctuation">.</span>Model<span class="token punctuation">.</span>delete<span class="token punctuation">(</span>FINE_TUNED_MODEL<span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="准备数据集" tabindex="-1"><a class="header-anchor" href="#准备数据集"><span>准备数据集</span></a></h2><p>微调是一种强大的技术，可用于创建特定于您的用例的新模型。<strong>在微调您的模型之前，我们强烈建议您阅读以下针对您的用例的最佳实践和<a href="https://platform.openai.com/docs/guides/fine-tuning/specific-guidelines" target="_blank" rel="noopener noreferrer">具体指南。</a></strong></p><h3 id="数据格式化" tabindex="-1"><a class="header-anchor" href="#数据格式化"><span>数据格式化</span></a></h3><p>要微调模型，您需要一组训练示例，每个训练示例都包含一个输入（“提示”）及其关联的输出（“补全”）。这与使用我们的基本模型明显不同，在基本模型中，您可能会在单个提示中输入详细说明或多个示例。</p><ul><li>每个提示都应以固定分隔符结尾，以在提示结束和补全开始时通知模型。通常效果很好的简单分隔符是<code>\\n\\n###\\n\\n</code>. 分隔符不应出现在任何提示中的其他地方。</li><li>由于我们的<a href="https://platform.openai.com/tokenizer" target="_blank" rel="noopener noreferrer">标记化</a>，每个补全都应该以空格开头，它用前面的空格标记大多数单词。</li><li>每次补全都应以固定的停止序列结束，以在补全结束时通知模型。停止序列可以是<code>\\n</code>、<code>###</code>或任何其他未出现在任补全成中的标记。</li><li>对于推理，您应该按照与创建训练数据集时相同的方式格式化提示，包括相同的分隔符。还指定相同的停止序列以正确截断完成。</li></ul><h3 id="一般最佳实践" tabindex="-1"><a class="header-anchor" href="#一般最佳实践"><span>一般最佳实践</span></a></h3><p>使用更多高质量的示例进行微调效果更好。要微调一个比使用我们的基本模型使用高质量提示更好地执行的模型，您应该提供至少几百个高质量的示例，最好由人类专家审查。从那里开始，性能往往会随着示例数量的每增加一倍而线性增加。增加示例的数量通常是提高性能的最佳和最可靠的方法。</p><p>分类器是最容易上手的模型。对于分类问题，我们建议使用 ada，经过微调后，它通常只会比功能更强大的模型稍微差一点，同时速度更快，成本更低。</p><p>如果您要对预先存在的数据集进行微调，而不是从头开始编写提示，请务必在可能的情况下手动检查您的数据是否存在令人反感或不准确的内容，或者如果数据集很大，请检查尽可能多的随机样本。</p><h3 id="具体准则" tabindex="-1"><a class="header-anchor" href="#具体准则"><span>具体准则</span></a></h3><p>微调可以解决多种问题，最佳使用方式可能取决于您的具体用例。下面，我们列出了最常见的微调用例和相应的指南。</p><ul><li>分类 <ul><li>情绪分析</li><li>该模型是否做出了不真实的陈述？</li><li>电子邮件分类的分类</li></ul></li><li>条件生成 <ul><li>根据维基百科文章撰写引人入胜的广告</li><li>实体提取</li><li>客户支持聊天机器人</li><li>基于技术属性列表的产品描述</li></ul></li></ul><h3 id="分类" tabindex="-1"><a class="header-anchor" href="#分类"><span>分类</span></a></h3><p>在分类问题中，提示中的每个输入都应分类到预定义的类别之一。对于此类问题，我们建议：</p><ul><li>在提示末尾使用分隔符，例如<code>\\n\\n###\\n\\n</code>. 当您最终向您的模型发出请求时，请记住还要附加此分隔符。</li><li>选择映射到单个<a href="https://platform.openai.com/tokenizer" target="_blank" rel="noopener noreferrer">标记</a>的类。在推理时，请指定，<code>max_tokens=1</code>因为您只需要第一个标记进行分类。</li><li>确保提示+补全不超过 2048 个标记，包括分隔符</li><li>目标是每个类至少 ~100 个例子</li><li>要获得类日志概率，您可以<code>logprobs=5</code>在使用模型时指定（对于 5 个类）</li><li>确保用于微调的数据集在结构和任务类型上与模型将用于的数据集非常相似</li></ul><h4 id="案例研究-模型是否做出了不真实的陈述" tabindex="-1"><a class="header-anchor" href="#案例研究-模型是否做出了不真实的陈述"><span>案例研究：模型是否做出了不真实的陈述？</span></a></h4><p>假设您希望确保您网站上的广告文字提及正确的产品和公司。换句话说，您要确保模型没有胡编乱造。您可能想要微调过滤掉不正确广告的分类器。</p><p>数据集可能类似于以下内容：</p><div class="language-json line-numbers-mode" data-highlighter="prismjs" data-ext="json" data-title="json"><pre><code><span class="line"><span class="token punctuation">{</span><span class="token property">&quot;prompt&quot;</span><span class="token operator">:</span><span class="token string">&quot;Company: BHFF insurance\\nProduct: allround insurance\\nAd:One stop shop for all your insurance needs!\\nSupported:&quot;</span><span class="token punctuation">,</span> <span class="token property">&quot;completion&quot;</span><span class="token operator">:</span><span class="token string">&quot; yes&quot;</span><span class="token punctuation">}</span></span>
<span class="line"><span class="token punctuation">{</span><span class="token property">&quot;prompt&quot;</span><span class="token operator">:</span><span class="token string">&quot;Company: Loft conversion specialists\\nProduct: -\\nAd:Straight teeth in weeks!\\nSupported:&quot;</span><span class="token punctuation">,</span> <span class="token property">&quot;completion&quot;</span><span class="token operator">:</span><span class="token string">&quot; no&quot;</span><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p>在上面的示例中，我们使用了包含公司名称、产品和相关广告的结构化输入。作为分隔符，我们使用<code>\\nSupported:</code>它清楚地将提示与完成分开。如果有足够数量的示例，分隔符不会产生太大差异（通常小于 0.4%），只要它没有出现在提示或补全中即可。</p><p>对于这个用例，我们微调了一个 ada 模型，因为它会更快、更便宜，而且性能将与更大的模型相当，因为它是一个分类任务。</p><p>现在我们可以通过发出完成请求来查询我们的模型。</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line"><span class="token function">curl</span> https://api.openai.com/v1/completions <span class="token punctuation">\\</span></span>
<span class="line">  <span class="token parameter variable">-H</span> <span class="token string">&#39;Content-Type: application/json&#39;</span> <span class="token punctuation">\\</span></span>
<span class="line">  <span class="token parameter variable">-H</span> <span class="token string">&#39;Authorization: Bearer YOUR_API_KEY&#39;</span> <span class="token punctuation">\\</span></span>
<span class="line">  <span class="token parameter variable">-d</span> <span class="token string">&#39;{</span>
<span class="line">  &quot;prompt&quot;: &quot;Company: Reliable accountants Ltd\\nProduct: Personal Tax help\\nAd:Best advice in town!\\nSupported:&quot;,</span>
<span class="line">  &quot;max_tokens&quot;: 1,</span>
<span class="line">  &quot;model&quot;: &quot;YOUR_FINE_TUNED_MODEL_NAME&quot;</span>
<span class="line">}&#39;</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>哪个将返回<code> yes</code>or <code>no</code>。</p><h4 id="案例研究-情绪分析" tabindex="-1"><a class="header-anchor" href="#案例研究-情绪分析"><span>案例研究：情绪分析</span></a></h4><p>假设您想要了解特定推文的正面或负面程度。数据集可能类似于以下内容：</p><div class="language-json line-numbers-mode" data-highlighter="prismjs" data-ext="json" data-title="json"><pre><code><span class="line"><span class="token punctuation">{</span><span class="token property">&quot;prompt&quot;</span><span class="token operator">:</span><span class="token string">&quot;Overjoyed with the new iPhone! -&gt;&quot;</span><span class="token punctuation">,</span> <span class="token property">&quot;completion&quot;</span><span class="token operator">:</span><span class="token string">&quot; positive&quot;</span><span class="token punctuation">}</span></span>
<span class="line"><span class="token punctuation">{</span><span class="token property">&quot;prompt&quot;</span><span class="token operator">:</span><span class="token string">&quot;@lakers disappoint for a third straight night https://t.co/38EFe43 -&gt;&quot;</span><span class="token punctuation">,</span> <span class="token property">&quot;completion&quot;</span><span class="token operator">:</span><span class="token string">&quot; negative&quot;</span><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p>对模型进行微调后，您可以通过<code>logprobs=2</code>在完成请求上设置来取回第一个完成标记的对数概率。正类别的概率越高，相对情绪就越高。</p><p>现在我们可以通过发出完成请求来查询我们的模型。</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line"><span class="token function">curl</span> https://api.openai.com/v1/completions <span class="token punctuation">\\</span></span>
<span class="line">  <span class="token parameter variable">-H</span> <span class="token string">&#39;Content-Type: application/json&#39;</span> <span class="token punctuation">\\</span></span>
<span class="line">  <span class="token parameter variable">-H</span> <span class="token string">&#39;Authorization: Bearer YOUR_API_KEY&#39;</span> <span class="token punctuation">\\</span></span>
<span class="line">  <span class="token parameter variable">-d</span> <span class="token string">&#39;{</span>
<span class="line">  &quot;prompt&quot;: &quot;https://t.co/f93xEd2 Excited to share my latest blog post! -&gt;&quot;,</span>
<span class="line">  &quot;max_tokens&quot;: 1,</span>
<span class="line">  &quot;model&quot;: &quot;YOUR_FINE_TUNED_MODEL_NAME&quot;</span>
<span class="line">}&#39;</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>哪个将返回：</p><div class="language-json line-numbers-mode" data-highlighter="prismjs" data-ext="json" data-title="json"><pre><code><span class="line"><span class="token punctuation">{</span></span>
<span class="line">  <span class="token property">&quot;id&quot;</span><span class="token operator">:</span> <span class="token string">&quot;cmpl-COMPLETION_ID&quot;</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;object&quot;</span><span class="token operator">:</span> <span class="token string">&quot;text_completion&quot;</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;created&quot;</span><span class="token operator">:</span> <span class="token number">1589498378</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;model&quot;</span><span class="token operator">:</span> <span class="token string">&quot;YOUR_FINE_TUNED_MODEL_NAME&quot;</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;choices&quot;</span><span class="token operator">:</span> <span class="token punctuation">[</span></span>
<span class="line">    <span class="token punctuation">{</span></span>
<span class="line">      <span class="token property">&quot;logprobs&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span></span>
<span class="line">        <span class="token property">&quot;text_offset&quot;</span><span class="token operator">:</span> <span class="token punctuation">[</span></span>
<span class="line">          <span class="token number">19</span></span>
<span class="line">        <span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token property">&quot;token_logprobs&quot;</span><span class="token operator">:</span> <span class="token punctuation">[</span></span>
<span class="line">          <span class="token number">-0.03597255</span></span>
<span class="line">        <span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token property">&quot;tokens&quot;</span><span class="token operator">:</span> <span class="token punctuation">[</span></span>
<span class="line">          <span class="token string">&quot; positive&quot;</span></span>
<span class="line">        <span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token property">&quot;top_logprobs&quot;</span><span class="token operator">:</span> <span class="token punctuation">[</span></span>
<span class="line">          <span class="token punctuation">{</span></span>
<span class="line">            <span class="token property">&quot; negative&quot;</span><span class="token operator">:</span> <span class="token number">-4.9785037</span><span class="token punctuation">,</span></span>
<span class="line">            <span class="token property">&quot; positive&quot;</span><span class="token operator">:</span> <span class="token number">-0.03597255</span></span>
<span class="line">          <span class="token punctuation">}</span></span>
<span class="line">        <span class="token punctuation">]</span></span>
<span class="line">      <span class="token punctuation">}</span><span class="token punctuation">,</span></span>
<span class="line"></span>
<span class="line">      <span class="token property">&quot;text&quot;</span><span class="token operator">:</span> <span class="token string">&quot; positive&quot;</span><span class="token punctuation">,</span></span>
<span class="line">      <span class="token property">&quot;index&quot;</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span></span>
<span class="line">      <span class="token property">&quot;finish_reason&quot;</span><span class="token operator">:</span> <span class="token string">&quot;length&quot;</span></span>
<span class="line">    <span class="token punctuation">}</span></span>
<span class="line">  <span class="token punctuation">]</span></span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="案例研究-电子邮件分类的分类" tabindex="-1"><a class="header-anchor" href="#案例研究-电子邮件分类的分类"><span>案例研究：电子邮件分类的分类</span></a></h4><p>假设您希望将收到的电子邮件归入大量预定义类别之一。对于大量类别的分类，我们建议您将这些类别转换为数字，最多可处理约 500 个类别。我们观察到，由于标记化，在数字前添加一个空格有时会对性能略有帮助。您可能希望按如下方式构建训练数据：</p><div class="language-json line-numbers-mode" data-highlighter="prismjs" data-ext="json" data-title="json"><pre><code><span class="line"><span class="token punctuation">{</span><span class="token property">&quot;prompt&quot;</span><span class="token operator">:</span><span class="token string">&quot;Subject: &lt;email_subject&gt;\\nFrom:&lt;customer_name&gt;\\nDate:&lt;date&gt;\\nContent:&lt;email_body&gt;\\n\\n###\\n\\n&quot;</span><span class="token punctuation">,</span> <span class="token property">&quot;completion&quot;</span><span class="token operator">:</span><span class="token string">&quot; &lt;numerical_category&gt;&quot;</span><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>例如：</p><div class="language-json line-numbers-mode" data-highlighter="prismjs" data-ext="json" data-title="json"><pre><code><span class="line"><span class="token punctuation">{</span><span class="token property">&quot;prompt&quot;</span><span class="token operator">:</span><span class="token string">&quot;Subject: Update my address\\nFrom:Joe Doe\\nTo:support@ourcompany.com\\nDate:2021-06-03\\nContent:Hi,\\nI would like to update my billing address to match my delivery address.\\n\\nPlease let me know once done.\\n\\nThanks,\\nJoe\\n\\n###\\n\\n&quot;</span><span class="token punctuation">,</span> <span class="token property">&quot;completion&quot;</span><span class="token operator">:</span><span class="token string">&quot; 4&quot;</span><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>在上面的示例中，我们使用了一封上限为 2043 个标记的传入电子邮件作为输入。（这允许使用 4 个标记分隔符和一个标记完成，总计为 2048。）作为分隔符，我们使用并删除了电子邮件中<code>\\n\\n###\\n\\n</code>出现的所有内容。<code>###</code></p><p><strong>条件生成</strong></p><p>条件生成是需要在给定某种输入的情况下生成内容的问题。这包括释义、总结、实体提取、编写给定规范的产品描述、聊天机器人等。对于此类问题，我们建议：</p><ul><li>在提示末尾使用分隔符，例如<code>\\n\\n###\\n\\n</code>. 当您最终向您的模型发出请求时，请记住还要附加此分隔符。</li><li>在完成结束时使用结束标记，例如<code> END</code></li><li>请记住在推理过程中将结束标记添加为停止序列，例如<code>stop=[&quot; END&quot;]</code></li><li>目标是至少 ~500 个示例</li><li>确保提示+完成不超过 2048 个标记，包括分隔符</li><li>确保示例具有高质量并遵循相同的所需格式</li><li>确保用于微调的数据集在结构和任务类型上与模型将用于的数据集非常相似</li><li>使用较低的学习率和仅 1-2 个时期往往更适合这些用例</li></ul><h4 id="案例研究-根据维基百科文章撰写引人入胜的广告" tabindex="-1"><a class="header-anchor" href="#案例研究-根据维基百科文章撰写引人入胜的广告"><span>案例研究：根据维基百科文章撰写引人入胜的广告</span></a></h4><p>这是一个生成用例，因此您需要确保提供的样本具有最高质量，因为微调模型将尝试模仿给定示例的风格（和错误）。一个好的起点是大约 500 个示例。示例数据集可能如下所示：</p><div class="language-json line-numbers-mode" data-highlighter="prismjs" data-ext="json" data-title="json"><pre><code><span class="line"><span class="token punctuation">{</span><span class="token property">&quot;prompt&quot;</span><span class="token operator">:</span><span class="token string">&quot;&lt;Product Name&gt;\\n&lt;Wikipedia description&gt;\\n\\n###\\n\\n&quot;</span><span class="token punctuation">,</span> <span class="token property">&quot;completion&quot;</span><span class="token operator">:</span><span class="token string">&quot; &lt;engaging ad&gt; END&quot;</span><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>例如：</p><div class="language-json line-numbers-mode" data-highlighter="prismjs" data-ext="json" data-title="json"><pre><code><span class="line"><span class="token punctuation">{</span><span class="token property">&quot;prompt&quot;</span><span class="token operator">:</span><span class="token string">&quot;Samsung Galaxy Feel\\nThe Samsung Galaxy Feel is an Android smartphone developed by Samsung Electronics exclusively for the Japanese market. The phone was released in June 2017 and was sold by NTT Docomo. It runs on Android 7.0 (Nougat), has a 4.7 inch display, and a 3000 mAh battery.\\nSoftware\\nSamsung Galaxy Feel runs on Android 7.0 (Nougat), but can be later updated to Android 8.0 (Oreo).\\nHardware\\nSamsung Galaxy Feel has a 4.7 inch Super AMOLED HD display, 16 MP back facing and 5 MP front facing cameras. It has a 3000 mAh battery, a 1.6 GHz Octa-Core ARM Cortex-A53 CPU, and an ARM Mali-T830 MP1 700 MHz GPU. It comes with 32GB of internal storage, expandable to 256GB via microSD. Aside from its software and hardware specifications, Samsung also introduced a unique a hole in the phone&#39;s shell to accommodate the Japanese perceived penchant for personalizing their mobile phones. The Galaxy Feel&#39;s battery was also touted as a major selling point since the market favors handsets with longer battery life. The device is also waterproof and supports 1seg digital broadcasts using an antenna that is sold separately.\\n\\n###\\n\\n&quot;</span><span class="token punctuation">,</span> <span class="token property">&quot;completion&quot;</span><span class="token operator">:</span><span class="token string">&quot;Looking for a smartphone that can do it all? Look no further than Samsung Galaxy Feel! With a slim and sleek design, our latest smartphone features high-quality picture and video capabilities, as well as an award winning battery life. END&quot;</span><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>这里我们使用了多行分隔符，因为维基百科文章包含多个段落和标题。我们还使用了一个简单的结束标记，以确保模型知道何时应该完成完成。</p><h4 id="案例研究-实体提取" tabindex="-1"><a class="header-anchor" href="#案例研究-实体提取"><span>案例研究：实体提取</span></a></h4><p>这类似于语言转换任务。为了提高性能，最好按字母顺序或按照它们在原始文本中出现的相同顺序对不同的提取实体进行排序。这将有助于模型跟踪需要按顺序生成的所有实体。数据集可能如下所示：</p><div class="language-json line-numbers-mode" data-highlighter="prismjs" data-ext="json" data-title="json"><pre><code><span class="line"><span class="token punctuation">{</span><span class="token property">&quot;prompt&quot;</span><span class="token operator">:</span><span class="token string">&quot;&lt;any text, for example news article&gt;\\n\\n###\\n\\n&quot;</span><span class="token punctuation">,</span> <span class="token property">&quot;completion&quot;</span><span class="token operator">:</span><span class="token string">&quot; &lt;list of entities, separated by a newline&gt; END&quot;</span><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>例如：</p><div class="language-json line-numbers-mode" data-highlighter="prismjs" data-ext="json" data-title="json"><pre><code><span class="line"><span class="token punctuation">{</span><span class="token property">&quot;prompt&quot;</span><span class="token operator">:</span><span class="token string">&quot;Portugal will be removed from the UK&#39;s green travel list from Tuesday, amid rising coronavirus cases and concern over a \\&quot;Nepal mutation of the so-called Indian variant\\&quot;. It will join the amber list, meaning holidaymakers should not visit and returnees must isolate for 10 days...\\n\\n###\\n\\n&quot;</span><span class="token punctuation">,</span> <span class="token property">&quot;completion&quot;</span><span class="token operator">:</span><span class="token string">&quot; Portugal\\nUK\\nNepal mutation\\nIndian variant END&quot;</span><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>多行分隔符效果最好，因为文本可能包含多行。理想情况下，输入提示的类型将高度多样化（新闻文章、维基百科页面、推文、法律文件），这反映了提取实体时可能遇到的文本。</p><h4 id="案例研究-客户支持聊天机器人" tabindex="-1"><a class="header-anchor" href="#案例研究-客户支持聊天机器人"><span>案例研究：客户支持聊天机器人</span></a></h4><p>聊天机器人通常会包含有关对话的相关上下文（订单详细信息）、到目前为止的对话摘要以及最近的消息。对于这个用例，相同的过去对话可以在数据集中生成多行，每次都有稍微不同的上下文，对于每个代理生成作为完成。这个用例将需要几千个示例，因为它可能会处理不同类型的请求和客户问题。为确保高质量的性能，我们建议审查对话样本以确保代理消息的质量。可以使用单独的文本转换微调模型生成摘要。数据集可能如下所示：</p><div class="language-json line-numbers-mode" data-highlighter="prismjs" data-ext="json" data-title="json"><pre><code><span class="line"><span class="token punctuation">{</span><span class="token property">&quot;prompt&quot;</span><span class="token operator">:</span><span class="token string">&quot;Summary: &lt;summary of the interaction so far&gt;\\n\\nSpecific information:&lt;for example order details in natural language&gt;\\n\\n###\\n\\nCustomer: &lt;message1&gt;\\nAgent: &lt;response1&gt;\\nCustomer: &lt;message2&gt;\\nAgent:&quot;</span><span class="token punctuation">,</span> <span class="token property">&quot;completion&quot;</span><span class="token operator">:</span><span class="token string">&quot; &lt;response2&gt;\\n&quot;</span><span class="token punctuation">}</span></span>
<span class="line"><span class="token punctuation">{</span><span class="token property">&quot;prompt&quot;</span><span class="token operator">:</span><span class="token string">&quot;Summary: &lt;summary of the interaction so far&gt;\\n\\nSpecific information:&lt;for example order details in natural language&gt;\\n\\n###\\n\\nCustomer: &lt;message1&gt;\\nAgent: &lt;response1&gt;\\nCustomer: &lt;message2&gt;\\nAgent: &lt;response2&gt;\\nCustomer: &lt;message3&gt;\\nAgent:&quot;</span><span class="token punctuation">,</span> <span class="token property">&quot;completion&quot;</span><span class="token operator">:</span><span class="token string">&quot; &lt;response3&gt;\\n&quot;</span><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p>在这里，我们有意分离不同类型的输入信息，但在提示和完成之间以相同的格式维护客户代理对话框。所有的完成都应该只由代理完成，我们可以<code>\\n</code>在进行推理时用作停止序列。</p><h4 id="案例研究-基于技术属性列表的产品描述" tabindex="-1"><a class="header-anchor" href="#案例研究-基于技术属性列表的产品描述"><span>案例研究：基于技术属性列表的产品描述</span></a></h4><p>在这里，将输入数据转换为自然语言很重要，这可能会带来卓越的性能。例如，以下格式：</p><div class="language-json line-numbers-mode" data-highlighter="prismjs" data-ext="json" data-title="json"><pre><code><span class="line"><span class="token punctuation">{</span><span class="token property">&quot;prompt&quot;</span><span class="token operator">:</span><span class="token string">&quot;Item=handbag, Color=army_green, price=$99, size=S-&gt;&quot;</span><span class="token punctuation">,</span> <span class="token property">&quot;completion&quot;</span><span class="token operator">:</span><span class="token string">&quot; This stylish small green handbag will add a unique touch to your look, without costing you a fortune.&quot;</span><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>不会像以下那样工作：</p><div class="language-json line-numbers-mode" data-highlighter="prismjs" data-ext="json" data-title="json"><pre><code><span class="line"><span class="token punctuation">{</span><span class="token property">&quot;prompt&quot;</span><span class="token operator">:</span><span class="token string">&quot;Item is a handbag. Colour is army green. Price is midrange. Size is small.-&gt;&quot;</span><span class="token punctuation">,</span> <span class="token property">&quot;completion&quot;</span><span class="token operator">:</span><span class="token string">&quot; This stylish small green handbag will add a unique touch to your look, without costing you a fortune.&quot;</span><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>为了获得高性能，请确保完成是基于所提供的描述。如果经常查阅外部内容，则以自动方式添加此类内容将提高性能。如果描述基于图像，则使用算法提取图像的文本描述可能会有所帮助。由于完成只有一个句子长，我们可以<code>.</code>在推理过程中用作停止序列。</p><h2 id="高级用法" tabindex="-1"><a class="header-anchor" href="#高级用法"><span>高级用法</span></a></h2><h3 id="自定义您的模型名称" tabindex="-1"><a class="header-anchor" href="#自定义您的模型名称"><span>自定义您的模型名称</span></a></h3><p><a href="https://platform.openai.com/docs/api-reference/fine-tunes/create#fine-tunes/create-suffix" target="_blank" rel="noopener noreferrer">您可以使用后缀</a>参数将最多 40 个字符的后缀添加到经过微调的模型名称中。</p><p>OpenAI 命令行界面：</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line">openai api fine_tunes.create <span class="token parameter variable">-t</span> test.jsonl <span class="token parameter variable">-m</span> ada <span class="token parameter variable">--suffix</span> <span class="token string">&quot;custom model name&quot;</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>结果名称将是：</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line">ada:ft-your-org:custom-model-name-2022-02-15-04-21-04</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h3 id="分析您的微调模型" tabindex="-1"><a class="header-anchor" href="#分析您的微调模型"><span>分析您的微调模型</span></a></h3><p>我们会在每个作业完成后附上一个结果文件。当您检索微调时以及查看微调中的事件时，将列出此结果文件 ID。您可以下载这些文件：</p><p>OpenAI 命令行界面：</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line">openai api fine_tunes.results <span class="token parameter variable">-i</span> <span class="token operator">&lt;</span>YOUR_FINE_TUNE_JOB_ID<span class="token operator">&gt;</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>CURL:</p><div class="language-text line-numbers-mode" data-highlighter="prismjs" data-ext="text" data-title="text"><pre><code><span class="line">curl https://api.openai.com/v1/files/$RESULTS_FILE_ID/content \\</span>
<span class="line">  -H &quot;Authorization: Bearer $OPENAI_API_KEY&quot; &gt; results.csv</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p>该<code>_results.csv</code>文件为每个训练步骤包含一行，其中一个步骤是指对一批数据的一次前向和反向传递。除步骤编号外，每行还包含与该步骤对应的以下字段：</p><ul><li><strong>elapsed_tokens</strong>：模型到目前为止已经看到的标记数（包括重复）</li><li><strong>elapsed_examples</strong>：模型到目前为止已经看到的示例数量（包括重复），其中一个示例是您的批次中的一个元素。例如，如果<code>batch_size = 4</code>，每一步将增加<code>elapsed_examples</code>4。</li><li><strong>training_loss</strong>：训练批次的损失</li><li><strong>training_sequence_accuracy</strong> ：训练批次中模型的预测标记与真实完成标记完全匹配的完成<strong>百分比</strong>。例如，如果 a<code>batch_size</code>为 3，如果您的数据包含补全 [ [1, 2] , [0, 5] , [4, 2] ] 和模型预测 [ [1, 1] , [0, 5] ，[4, 2] ]，这个准确度将是 2/3 = 0.67</li><li><strong>training_token_accuracy</strong> ：模型正确预测的训练批次中<strong>标记</strong>的百分比。例如，如果 a<code>batch_size</code>为 3，如果您的数据包含补全 [ [1, 2] , [0, 5] , [4, 2] ] 和模型预测 [ [1, 1] , [0, 5] ，[4, 2] ]，这个准确度将是 5/6 = 0.83</li></ul><h3 id="分类特定指标" tabindex="-1"><a class="header-anchor" href="#分类特定指标"><span>分类特定指标</span></a></h3><p>我们还提供了在结果文件中生成其他特定于分类的指标的选项，例如准确性和加权 F1 分数。这些指标是根据完整的验证集和微调结束时定期计算的。您将在结果文件中看到它们作为附加列。</p><p>要启用此功能，请设置参数<code>--compute_classification_metrics</code>。此外，您必须提供一个验证文件，并为多类分类设置<code>classification_n_classes</code>参数，或<code>classification_positive_class</code>为二元分类设置参数。</p><p>OpenAI 命令行界面：</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line"><span class="token comment"># 对于多类分类</span></span>
<span class="line">openai api fine_tunes.create <span class="token punctuation">\\</span></span>
<span class="line">  <span class="token parameter variable">-t</span> <span class="token operator">&lt;</span>TRAIN_FILE_ID_OR_PATH<span class="token operator">&gt;</span> <span class="token punctuation">\\</span></span>
<span class="line">  <span class="token parameter variable">-v</span> <span class="token operator">&lt;</span>VALIDATION_FILE_OR_PATH<span class="token operator">&gt;</span> <span class="token punctuation">\\</span></span>
<span class="line">  <span class="token parameter variable">-m</span> <span class="token operator">&lt;</span>MODEL<span class="token operator">&gt;</span> <span class="token punctuation">\\</span></span>
<span class="line">  <span class="token parameter variable">--compute_classification_metrics</span> <span class="token punctuation">\\</span></span>
<span class="line">  <span class="token parameter variable">--classification_n_classes</span> <span class="token operator">&lt;</span>N_CLASSES<span class="token operator">&gt;</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 对于二分类</span></span>
<span class="line">openai api fine_tunes.create <span class="token punctuation">\\</span></span>
<span class="line">  <span class="token parameter variable">-t</span> <span class="token operator">&lt;</span>TRAIN_FILE_ID_OR_PATH<span class="token operator">&gt;</span> <span class="token punctuation">\\</span></span>
<span class="line">  <span class="token parameter variable">-v</span> <span class="token operator">&lt;</span>VALIDATION_FILE_OR_PATH<span class="token operator">&gt;</span> <span class="token punctuation">\\</span></span>
<span class="line">  <span class="token parameter variable">-m</span> <span class="token operator">&lt;</span>MODEL<span class="token operator">&gt;</span> <span class="token punctuation">\\</span></span>
<span class="line">  <span class="token parameter variable">--compute_classification_metrics</span> <span class="token punctuation">\\</span></span>
<span class="line">  <span class="token parameter variable">--classification_n_classes</span> <span class="token number">2</span> <span class="token punctuation">\\</span></span>
<span class="line">  <span class="token parameter variable">--classification_positive_class</span> <span class="token operator">&lt;</span>POSITIVE_CLASS_FROM_DATASET<span class="token operator">&gt;</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>如果您设置以下指标将显示在您的<a href="https://platform.openai.com/docs/guides/fine-tuning/analyzing-your-fine-tuned-model" target="_blank" rel="noopener noreferrer">结果文件</a><code>--compute_classification_metrics</code>中：</p><h5 id="对于多类分类" tabindex="-1"><a class="header-anchor" href="#对于多类分类"><span>对于多类分类</span></a></h5><ul><li><strong>分类/准确度</strong>：准确度</li><li><strong>classification/weighted_f1_score</strong> : 加权 F-1 分数</li></ul><h5 id="对于二进制分类" tabindex="-1"><a class="header-anchor" href="#对于二进制分类"><span>对于二进制分类</span></a></h5><p>以下指标基于 0.5 的分类阈值（即当概率 &gt; 0.5 时，示例被分类为属于正类。）</p><ul><li><strong>分类/准确度</strong></li><li><strong>分类/精度</strong></li><li><strong>分类/召回</strong></li><li><strong>分类/f{beta}</strong></li><li><strong>分类/auroc</strong> - AUROC</li><li><strong>分类/auprc</strong> - AUPRC</li></ul><p>请注意，这些评估假设您正在为将标记化为单个标记的类使用文本标签，如上所述。如果这些条件不成立，您得到的数字很可能是错误的。</p><h3 id="验证" tabindex="-1"><a class="header-anchor" href="#验证"><span>验证</span></a></h3><p>您可以保留一些数据以供验证。验证文件与训练文件具有完全相同的格式，并且您的训练数据和验证数据应该互斥。</p><p>如果您在创建微调作业时包含验证文件，则生成的结果文件将包括对微调模型在训练期间定期对验证数据执行情况的评估。</p><p>OpenAI 命令行界面：</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line">openai api fine_tunes.create <span class="token parameter variable">-t</span> <span class="token operator">&lt;</span>TRAIN_FILE_ID_OR_PATH<span class="token operator">&gt;</span> <span class="token punctuation">\\</span></span>
<span class="line">  <span class="token parameter variable">-v</span> <span class="token operator">&lt;</span>VALIDATION_FILE_ID_OR_PATH<span class="token operator">&gt;</span> <span class="token punctuation">\\</span></span>
<span class="line">  <span class="token parameter variable">-m</span> <span class="token operator">&lt;</span>MODEL<span class="token operator">&gt;</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>如果您提供了验证文件，我们会在训练期间定期计算批量验证数据的指标。您将在结果文件中看到以下附加指标：</p><ul><li><strong>validation_loss</strong>：验证批次的损失</li><li><strong>validation_sequence_accuracy</strong>：验证批次中模型的预测标记与真实完成标记完全匹配的完成百分比。例如，如果 a<code>batch_size</code>为 3，如果您的数据包含完成 [ [1, 2] , [0, 5] , [4, 2] ] 和模型预测 [ [1, 1] , [0, 5] ，[4, 2] ]，这个准确度将是 2/3 = 0.67</li><li><strong>validation_token_accuracy</strong>：模型正确预测的验证批次中标记的百分比。例如，如果 a<code>batch_size</code>为 3，如果您的数据包含完成 [ [1, 2] , [0, 5] , [4, 2] ] 和模型预测 [ [1, 1] , [0, 5] ，[4, 2] ]，这个准确度将是 5/6 = 0.83</li></ul><h2 id="超参数" tabindex="-1"><a class="header-anchor" href="#超参数"><span>超参数</span></a></h2><p>我们选择了适用于一系列用例的默认超参数。唯一需要的参数是训练文件。</p><p>也就是说，调整用于微调的超参数通常可以产生产生更高质量输出的模型。特别是，您可能需要配置以下内容：</p><ul><li><code>model</code>：要微调的基本模型的名称。您可以选择“ada”、“babbage”、“curie”或“davinci”之一。要了解有关这些模型的更多信息，请参阅<a href="https://platform.openai.com/docs/models" target="_blank" rel="noopener noreferrer">模型</a>文档。</li><li><code>n_epochs</code>- 默认为 4。训练模型的时期数。一个纪元指的是训练数据集的一个完整周期。</li><li><code>batch_size</code>- 默认为训练集中示例数量的 0.2%，上限为 256。批量大小是用于训练单个正向和反向传递的训练示例数。总的来说，我们发现更大的批次大小往往更适用于更大的数据集。</li><li><code>learning_rate_multiplier</code>- 默认为 0.05、0.1 或 0.2，具体取决于 final <code>batch_size</code>。微调学习率是用于预训练的原始学习率乘以该乘数。我们建议使用 0.02 到 0.2 范围内的值进行试验，以查看产生最佳结果的值。根据经验，我们发现较大的学习率通常在较大的批量大小下表现更好。</li><li><code>compute_classification_metrics</code>- 默认为假。如果为 True，为了对分类任务进行微调，在每个 epoch 结束时在验证集上计算特定于分类的指标（准确性、F-1 分数等）。</li></ul><p>要配置这些额外的超参数，请通过 OpenAI CLI 上的命令行标志传递它们，例如：</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line">openai api fine_tunes.create <span class="token punctuation">\\</span></span>
<span class="line">  <span class="token parameter variable">-t</span> file-JD89ePi5KMsB3Tayeli5ovfW <span class="token punctuation">\\</span></span>
<span class="line">  <span class="token parameter variable">-m</span> ada <span class="token punctuation">\\</span></span>
<span class="line">  <span class="token parameter variable">--n_epochs</span> <span class="token number">1</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="从微调模型继续微调" tabindex="-1"><a class="header-anchor" href="#从微调模型继续微调"><span>从微调模型继续微调</span></a></h3><p>如果您已经为您的任务微调了一个模型，并且现在有您想要合并的额外训练数据，您可以从模型继续微调。这将创建一个从所有训练数据中学习的模型，而无需从头开始重新训练。</p><p>为此，请在创建新的微调作业时传入微调后的模型名称（例如<code>-m curie:ft-&lt;org&gt;-&lt;date&gt;</code>）。其他训练参数不必更改，但是如果您的新训练数据比以前的训练数据小得多，您可能会发现减少<code>learning_rate_multiplier</code>2 到 4 倍很有用。</p><h3 id="权重和偏差" tabindex="-1"><a class="header-anchor" href="#权重和偏差"><span>权重和偏差</span></a></h3><p>您可以将微调与<a href="https://wandb.me/openai-docs" target="_blank" rel="noopener noreferrer">权重和偏差</a>同步以跟踪实验、模型和数据集。</p><p>要开始使用，您需要一个<a href="https://wandb.me/openai-docs" target="_blank" rel="noopener noreferrer">Weights &amp;</a> Biases 帐户和一个付费的 OpenAI 计划。为确保您使用的是最新版本的<code>openai</code>and <code>wandb</code>，请运行：</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line">pip <span class="token function">install</span> <span class="token parameter variable">--upgrade</span> openai wandb</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>要将微调与权重和偏差同步，请运行：</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line">openai wandb <span class="token function">sync</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>您可以阅读<a href="https://wandb.me/openai-docs" target="_blank" rel="noopener noreferrer">权重和偏差文档</a>以获取有关此集成的更多信息。</p><h2 id="示例笔记本" tabindex="-1"><a class="header-anchor" href="#示例笔记本"><span>示例笔记本</span></a></h2><h3 id="分类-1" tabindex="-1"><a class="header-anchor" href="#分类-1"><span>分类</span></a></h3><p><a href="https://github.com/openai/openai-cookbook/blob/main/examples/Fine-tuned_classification.ipynb" target="_blank" rel="noopener noreferrer">微调分类.ipynb</a></p><p>此笔记本将演示如何微调模型，该模型可以对一段输入文本是否与棒球或曲棍球相关进行分类。我们将在<a href="https://github.com/openai/openai-cookbook/blob/main/examples/Fine-tuned_classification.ipynb" target="_blank" rel="noopener noreferrer">笔记本中分</a>四个步骤执行此任务：</p><ol><li><strong>数据探索</strong>将概述数据源和示例</li><li><strong>数据准备</strong>会将我们的数据源变成一个jsonl文件，可以用来微调</li><li><strong>微调</strong>将启动微调工作并解释生成的模型的性能</li><li><strong>使用该模型</strong>将演示向微调模型发出请求以获得预测。</li></ol><h3 id="问题解答" tabindex="-1"><a class="header-anchor" href="#问题解答"><span>问题解答</span></a></h3><p><a href="https://github.com/openai/openai-cookbook/blob/main/examples/fine-tuned_qa/olympics-1-collect-data.ipynb" target="_blank" rel="noopener noreferrer">奥运会-1</a><a href="https://github.com/openai/openai-cookbook/blob/main/examples/fine-tuned_qa/olympics-2-create-qa.ipynb" target="_blank" rel="noopener noreferrer">奥运会-2</a><a href="https://github.com/openai/openai-cookbook/blob/main/examples/fine-tuned_qa/olympics-3-train-qa.ipynb" target="_blank" rel="noopener noreferrer">奥运会-3</a></p><p>这个项目的想法是基于提供的文本的几段来创建一个问答模型。当答案包含在段落中时，基本 GPT-3 模型在回答问题方面做得很好，但是如果答案不包含在内，基本模型往往会尽力回答，这通常会导致混淆答案。</p><p>为了创建一个仅在有足够上下文的情况下才回答问题的模型，我们首先创建一个基于文本段落的问题和答案数据集。为了训练模型仅在出现答案时回答，我们还添加了对抗性示例，其中问题与上下文不匹配。在这些情况下，我们要求模型输出“没有足够的上下文来回答问题”。</p><p>我们将在三个笔记本中执行此任务：</p><ol><li><a href="https://github.com/openai/openai-cookbook/blob/main/examples/fine-tuned_qa/olympics-1-collect-data.ipynb" target="_blank" rel="noopener noreferrer">第一个笔记本</a>侧重于收集最近的数据，这些数据是 GPT-3 在预训练期间没有看到的。我们选择了 2020 年奥运会（实际发生在 2021 年夏天）的主题，并下载了 713 个独特的页面。我们按各个部分组织数据集，这些部分将作为提问和回答问题的背景。</li><li><a href="https://github.com/openai/openai-cookbook/blob/main/examples/fine-tuned_qa/olympics-2-create-qa.ipynb" target="_blank" rel="noopener noreferrer">第二个笔记本</a>将利用 Davinci-instruct 根据维基百科部分提出一些问题，并根据该部分回答这些问题。</li><li><a href="https://github.com/openai/openai-cookbook/blob/main/examples/fine-tuned_qa/olympics-3-train-qa.ipynb" target="_blank" rel="noopener noreferrer">第三个笔记本</a>将利用上下文、问题和答案对的数据集来额外创建对抗性问题和上下文对，其中问题不是在该上下文中生成的。在这些情况下，系统将提示模型回答“没有足够的上下文来回答问题”。我们还将训练一个鉴别器模型，该模型预测是否可以根据上下文回答问题。</li></ol>`,187)]))}const r=s(p,[["render",o],["__file","微调.html.vue"]]),c=JSON.parse('{"path":"/guides/%E5%BE%AE%E8%B0%83.html","title":"微调","lang":"zh-cn","frontmatter":{},"headers":[{"level":1,"title":"微调","slug":"微调","link":"#微调","children":[{"level":2,"title":"介绍","slug":"介绍","link":"#介绍","children":[]},{"level":2,"title":"准备训练数据","slug":"准备训练数据","link":"#准备训练数据","children":[]},{"level":2,"title":"准备数据集","slug":"准备数据集","link":"#准备数据集","children":[{"level":3,"title":"数据格式化","slug":"数据格式化","link":"#数据格式化","children":[]},{"level":3,"title":"一般最佳实践","slug":"一般最佳实践","link":"#一般最佳实践","children":[]},{"level":3,"title":"具体准则","slug":"具体准则","link":"#具体准则","children":[]},{"level":3,"title":"分类","slug":"分类","link":"#分类","children":[]}]},{"level":2,"title":"高级用法","slug":"高级用法","link":"#高级用法","children":[{"level":3,"title":"自定义您的模型名称","slug":"自定义您的模型名称","link":"#自定义您的模型名称","children":[]},{"level":3,"title":"分析您的微调模型","slug":"分析您的微调模型","link":"#分析您的微调模型","children":[]},{"level":3,"title":"分类特定指标","slug":"分类特定指标","link":"#分类特定指标","children":[]},{"level":3,"title":"验证","slug":"验证","link":"#验证","children":[]}]},{"level":2,"title":"超参数","slug":"超参数","link":"#超参数","children":[{"level":3,"title":"从微调模型继续微调","slug":"从微调模型继续微调","link":"#从微调模型继续微调","children":[]},{"level":3,"title":"权重和偏差","slug":"权重和偏差","link":"#权重和偏差","children":[]}]},{"level":2,"title":"示例笔记本","slug":"示例笔记本","link":"#示例笔记本","children":[{"level":3,"title":"分类","slug":"分类-1","link":"#分类-1","children":[]},{"level":3,"title":"问题解答","slug":"问题解答","link":"#问题解答","children":[]}]}]}],"git":{},"filePathRelative":"guides/微调.md"}');export{r as comp,c as data};
